# ã€å…³äº BLIP-2 ã€‘é‚£äº›ä½ ä¸çŸ¥é“çš„äº‹

> [BLIP-2 æ¨¡å‹æ–‡æ¡£](https://hf.co/docs/transformers/main/en/model_doc/blip-2)

> [BLIP-2 è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/2301.12597.pdf)

## ä¸€ã€å‰è¨€

æœ¬æ–‡å°†ä»‹ç»æ¥è‡ª Salesforce ç ”ç©¶é™¢çš„ BLIP-2 æ¨¡å‹ï¼Œå®ƒæ”¯æŒä¸€æ•´å¥—æœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œä¸”å·²é›†æˆå…¥ ğŸ¤— Transformersã€‚æˆ‘ä»¬å°†å‘ä½ å±•ç¤ºå¦‚ä½•å°†å…¶ç”¨äºå›¾åƒå­—å¹•ç”Ÿæˆã€æœ‰æç¤ºå›¾åƒå­—å¹•ç”Ÿæˆã€è§†è§‰é—®ç­”åŠåŸºäºèŠå¤©çš„æç¤ºè¿™äº›åº”ç”¨åœºæ™¯ã€‚

## äºŒã€åŠ¨æœº

è¿‘å¹´æ¥ï¼Œè®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå„è‡ªéƒ½å–å¾—äº†é£é€Ÿå‘å±•ã€‚ä½†è®¸å¤šå®é™…é—®é¢˜æœ¬è´¨ä¸Šå…¶å®æ˜¯å¤šæ¨¡æ€çš„ï¼Œå³å®ƒä»¬åŒæ—¶æ¶‰åŠå‡ ç§ä¸åŒå½¢å¼çš„æ•°æ®ï¼Œå¦‚å›¾åƒå’Œæ–‡æœ¬ã€‚å› æ­¤ï¼Œéœ€è¦è§†è§‰è¯­è¨€æ¨¡å‹æ¥å¸®åŠ©è§£å†³ä¸€ç³»åˆ—ç»„åˆæ¨¡æ€çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬çš„æŠ€æœ¯æ‰èƒ½æœ€ç»ˆå¾—åˆ°å¹¿æ³›è½åœ°ã€‚**è§†è§‰è¯­è¨€æ¨¡å‹å¯ä»¥å¤„ç†çš„ä¸€äº› å›¾ç”Ÿæ–‡ ä»»åŠ¡åŒ…æ‹¬å›¾åƒå­—å¹•ç”Ÿæˆã€å›¾æ–‡æ£€ç´¢ä»¥åŠè§†è§‰é—®ç­”**ã€‚å›¾åƒå­—å¹•ç”Ÿæˆå¯ä»¥ç”¨äºè§†éšœäººå£«è¾…åŠ©ã€åˆ›å»ºæœ‰ç”¨çš„äº§å“æè¿°ã€è¯†åˆ«éæ–‡æœ¬æ¨¡æ€çš„ä¸å½“å†…å®¹ç­‰ã€‚å›¾æ–‡æ£€ç´¢å¯ä»¥ç”¨äºå¤šæ¨¡æ€æœç´¢ï¼Œä¹Ÿå¯ç”¨äºè‡ªåŠ¨é©¾é©¶åœºåˆã€‚è§†è§‰é—®ç­”å¯ä»¥åŠ©åŠ›æ•™è‚²è¡Œä¸šã€ä½¿èƒ½å¤šæ¨¡æ€èŠå¤©æœºå™¨äººï¼Œè¿˜å¯ç”¨äºå„ç§ç‰¹å®šé¢†åŸŸçš„ä¿¡æ¯æ£€ç´¢åº”ç”¨ã€‚

ç°ä»£è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€æ¨¡å‹åœ¨èƒ½åŠ›è¶Šæ¥è¶Šå¼ºå¤§çš„åŒæ—¶ï¼Œæ¨¡å‹å°ºå¯¸ä¹Ÿéšä¹‹æ˜¾è‘—å¢å¤§ã€‚ç”±äºå½“å‰è¿›è¡Œä¸€æ¬¡å•æ¨¡æ€æ¨¡å‹çš„é¢„è®­ç»ƒæ—¢è€—è´¹èµ„æºåˆæ˜‚è´µï¼Œå› æ­¤ç«¯åˆ°ç«¯è§†è§‰è¯­è¨€é¢„è®­ç»ƒçš„æˆæœ¬ä¹Ÿå·²å˜å¾—è¶Šæ¥è¶Šé«˜ã€‚

**BLIP-2 é€šè¿‡å¼•å…¥ä¸€ç§æ–°çš„è§†è§‰è¯­è¨€é¢„è®­ç»ƒèŒƒå¼æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œè¯¥èŒƒå¼å¯ä»¥ä»»æ„ç»„åˆå¹¶å……åˆ†åˆ©ç”¨ä¸¤ä¸ªé¢„è®­ç»ƒå¥½çš„è§†è§‰ç¼–ç å™¨å’Œ LLMï¼Œè€Œæ— é¡»ç«¯åˆ°ç«¯åœ°é¢„è®­ç»ƒæ•´ä¸ªæ¶æ„ã€‚è¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥åœ¨å¤šä¸ªè§†è§‰è¯­è¨€ä»»åŠ¡ä¸Šå®ç°æœ€å…ˆè¿›çš„ç»“æœï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘è®­ç»ƒå‚æ•°é‡å’Œé¢„è®­ç»ƒæˆæœ¬**ã€‚æ­¤å¤–ï¼Œè¿™ç§æ–¹æ³•ä¸ºå¤šæ¨¡æ€ChatGPT ç±»åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚

## ä¸‰ã€BLIP-2 æ¨¡å‹ç»“æ„

BLIP-2 é€šè¿‡**åœ¨å†»ç»“çš„é¢„è®­ç»ƒå›¾åƒç¼–ç å™¨å’Œå†»ç»“çš„é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ä¹‹é—´æ·»åŠ ä¸€ä¸ªè½»é‡çº§ æŸ¥è¯¢ Transformer (Query Transformer, Q-Former) æ¥å¼¥åˆè§†è§‰å’Œè¯­è¨€æ¨¡å‹ä¹‹é—´çš„æ¨¡æ€éš”é˜‚ (modality gap)**ã€‚åœ¨æ•´ä¸ªæ¨¡å‹ä¸­ï¼ŒQ-Former æ˜¯å”¯ä¸€çš„å¯è®­ç»ƒæ¨¡å—ï¼Œè€Œå›¾åƒç¼–ç å™¨å’Œè¯­è¨€æ¨¡å‹å§‹ç»ˆä¿æŒå†»ç»“çŠ¶æ€ã€‚

![](img/20230309093244.png)

### 3.1 Q-Former æ¨¡å‹ç»“æ„

Q-Former æ˜¯ä¸€ä¸ª transformer æ¨¡å‹ï¼Œå®ƒç”±ä¸¤ä¸ªå­æ¨¡å—ç»„æˆï¼Œè¿™ä¸¤ä¸ªå­æ¨¡å—å…±äº«ç›¸åŒçš„è‡ªæ³¨æ„åŠ›å±‚:

- ä¸å†»ç»“çš„å›¾åƒç¼–ç å™¨äº¤äº’çš„å›¾åƒ transformerï¼Œç”¨äºè§†è§‰ç‰¹å¾æå–
- æ–‡æœ¬ transformerï¼Œç”¨ä½œæ–‡æœ¬ç¼–ç å™¨å’Œè§£ç å™¨

![](img/20230309093523.png)

å›¾åƒ transformer ä»å›¾åƒç¼–ç å™¨ä¸­æå–å›ºå®šæ•°é‡çš„è¾“å‡ºç‰¹å¾ï¼Œè¿™é‡Œç‰¹å¾çš„ä¸ªæ•°ä¸è¾“å…¥å›¾åƒåˆ†è¾¨ç‡æ— å…³ã€‚åŒæ—¶ï¼Œå›¾åƒ transformer æ¥æ”¶è‹¥å¹²æŸ¥è¯¢åµŒå…¥ä½œä¸ºè¾“å…¥ï¼Œè¿™äº›æŸ¥è¯¢åµŒå…¥æ˜¯å¯è®­ç»ƒçš„ã€‚è¿™äº›æŸ¥è¯¢è¿˜å¯ä»¥é€šè¿‡ç›¸åŒçš„è‡ªæ³¨æ„åŠ›å±‚ä¸æ–‡æœ¬è¿›è¡Œäº¤äº’ (è¯‘è€…æ³¨: è¿™é‡Œçš„ç›¸åŒæ˜¯æŒ‡å›¾åƒ transformer å’Œæ–‡æœ¬ transformer å¯¹åº”çš„è‡ªæ³¨æ„åŠ›å±‚æ˜¯å…±äº«çš„)ã€‚

### 3.2 Q-Former é¢„è®­ç»ƒé˜¶æ®µ

- ç¬¬ä¸€é˜¶æ®µï¼Œå›¾åƒç¼–ç å™¨è¢«å†»ç»“ï¼ŒQ-Former é€šè¿‡ä¸‰ä¸ªæŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒ:
  - **å›¾æ–‡å¯¹æ¯”æŸå¤± (image-text contrastive loss)**: æ¯ä¸ªæŸ¥è¯¢çš„è¾“å‡ºéƒ½ä¸æ–‡æœ¬è¾“å‡ºçš„ CLS è¯å…ƒè®¡ç®—æˆå¯¹ç›¸ä¼¼åº¦ï¼Œå¹¶ä»ä¸­é€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„ä¸€ä¸ªæœ€ç»ˆè®¡ç®—å¯¹æ¯”æŸå¤±ã€‚åœ¨è¯¥æŸå¤±å‡½æ•°ä¸‹ï¼ŒæŸ¥è¯¢åµŒå…¥å’Œæ–‡æœ¬ä¸ä¼š â€œçœ‹åˆ°â€ å½¼æ­¤ã€‚
  - **åŸºäºå›¾åƒçš„æ–‡æœ¬ç”ŸæˆæŸå¤±**: æŸ¥è¯¢å†…éƒ¨å¯ä»¥ç›¸äº’è®¡ç®—æ³¨æ„åŠ›ä½†ä¸è®¡ç®—æ–‡æœ¬è¯å…ƒå¯¹æŸ¥è¯¢çš„æ³¨æ„åŠ›ï¼ŒåŒæ—¶æ–‡æœ¬å†…éƒ¨çš„è‡ªæ³¨æ„åŠ›ä½¿ç”¨å› æœæ©ç ä¸”éœ€è®¡ç®—æ‰€æœ‰æŸ¥è¯¢å¯¹æ–‡æœ¬çš„æ³¨æ„åŠ›ã€‚
  - **å›¾æ–‡åŒ¹é…æŸå¤± (image-text matching loss)**: æŸ¥è¯¢å’Œæ–‡æœ¬å¯ä»¥çœ‹åˆ°å½¼æ­¤ï¼Œæœ€ç»ˆè·å¾—ä¸€ä¸ªå‡ ç‡ (logit) ç”¨ä»¥è¡¨ç¤ºæ–‡å­—ä¸å›¾åƒæ˜¯å¦åŒ¹é…ã€‚è¿™é‡Œï¼Œä½¿ç”¨éš¾ä¾‹æŒ–æ˜æŠ€æœ¯ (hard negative mining) æ¥ç”Ÿæˆè´Ÿæ ·æœ¬ã€‚

- ç¬¬äºŒé˜¶æ®µï¼š
  - ç¬¬ä¸€é˜¶æ®µè¾“å‡ºï¼šå›¾åƒ transformer ä½œä¸ºä¸€ä¸ªä¿¡æ¯ç“¶é¢ˆ (information bottleneck)ï¼ŒæŸ¥è¯¢åµŒå…¥ç»è¿‡å®ƒåï¼Œå…¶è¾“å‡ºåµŒå…¥å·²ç»ä¸ä»…ä»…åŒ…å«äº†è§†è§‰ä¿¡æ¯ï¼Œè€Œä¸”åŒ…å«äº†ä¸æ–‡æœ¬ç›¸å…³çš„è§†è§‰ä¿¡æ¯ã€‚
  - ç¬¬ä¸€é˜¶æ®µè¾“å‡ºåµŒå…¥ç”¨ä½œç¬¬äºŒé˜¶æ®µ LLM è¾“å…¥çš„è§†è§‰å‰ç¼€ã€‚è¯¥é¢„è®­ç»ƒé˜¶æ®µä¸»è¦æ¶‰åŠä¸€ä¸ªä»¥åŸºäºå›¾åƒçš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼ŒæŸå¤±å‡½æ•°ä½¿ç”¨å› æœ LM æŸå¤±ã€‚

## å››ã€é€šè¿‡ Hugging Face Transformers ä½¿ç”¨ BLIP-2

### 4.1 æ¨¡å‹åŠ è½½

ä½¿ç”¨ Hugging Face Transformersï¼Œä½ å¯ä»¥è½»æ¾ä¸‹è½½å¹¶åœ¨ä½ è‡ªå·±çš„å›¾åƒä¸Šè¿è¡Œé¢„è®­ç»ƒçš„ BLIP-2 æ¨¡å‹ã€‚å¦‚æœä½ æƒ³è·‘è·‘æœ¬æ–‡ä¸­çš„ç¤ºä¾‹ï¼Œè¯·ç¡®ä¿ä½¿ç”¨å¤§æ˜¾å­˜ GPUã€‚

æˆ‘ä»¬ä»å®‰è£… Transformers å¼€å§‹ã€‚ç”±äºæ­¤æ¨¡å‹æ˜¯æœ€è¿‘æ‰æ·»åŠ åˆ° Transformers ä¸­çš„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä»æºä»£ç å®‰è£… Transformers:

```s
pip install git+https://github.com/huggingface/transformers.git
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¾“å…¥å›¾åƒã€‚ã€Šçº½çº¦å®¢ã€‹æ¯å‘¨éƒ½ä¼šé¢å‘å…¶è¯»è€…ä¸¾åŠä¸€åœº å¡é€šå­—å¹•æ¯”èµ›ã€‚æˆ‘ä»¬ä»ä¸­å–ä¸€å¼ å¡é€šå›¾åƒè¾“å…¥ç»™ BLIP-2 ç”¨äºæµ‹è¯•ã€‚

å¡é€šå­—æ¯æ¯”èµ›é“¾æ¥: https://www.newyorker.com/cartoons/contest#thisweek

```s
import requests
from PIL import Image

url = 'https://media.newyorker.com/cartoons/63dc6847be24a6a76d90eb99/master/w_1160,c_limit/230213_a26611_838.jpg'
image = Image.open (requests.get (url, stream=True).raw).convert ('RGB')  
display (image.resize ((596, 437)))
```

![](img/20230309094440.png)

ç°åœ¨æˆ‘ä»¬æœ‰ä¸€å¼ è¾“å…¥å›¾åƒäº†ï¼Œè¿˜éœ€è¦ä¸€ä¸ªé¢„è®­ç»ƒè¿‡çš„ BLIP-2 æ¨¡å‹å’Œç›¸åº”çš„é¢„å¤„ç†å™¨æ¥å¤„ç†è¾“å…¥ã€‚ä½  å¯ä»¥åœ¨ Hugging Face Hub ä¸Šæ‰¾åˆ°æ‰€æœ‰å¯ç”¨çš„é¢„è®­ç»ƒ checkpoints åˆ—è¡¨ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å°†åŠ è½½ä¸€ä¸ªä½¿ç”¨ Meta AI çš„é¢„è®­ç»ƒ OPT æ¨¡å‹çš„ BLIP-2 checkpointï¼Œè¯¥ OPT æ¨¡å‹å…·æœ‰ 27 äº¿ä¸ªå‚æ•°ã€‚

```s
from transformers import AutoProcessor, Blip2ForConditionalGeneration
import torch

processor = AutoProcessor.from_pretrained ("Salesforce/blip2-opt-2.7b")
model = Blip2ForConditionalGeneration.from_pretrained ("Salesforce/blip2-opt-2.7b", torch_dtype=torch.float16)
```

è¯·æ³¨æ„ï¼Œä½ æš‚æ—¶è¿˜æ— æ³•ä½¿ç”¨ Auto API (ä¾‹å¦‚ AutoModelForXXX) æ¥åŠ è½½ BLIP-2 æ¨¡å‹ï¼Œè¿™ç§æƒ…å†µåœ¨ Hugging Face ä¸­æ¯”è¾ƒå°‘è§ã€‚ä½ éœ€è¦æ˜¾å¼ä½¿ç”¨ Blip2ForConditionalGeneration æ¥åŠ è½½ BLIP-2 æ¨¡å‹ã€‚è™½ç„¶è‡ªåŠ¨è·å–æ¨¡å‹è¿˜ä¸èƒ½åšåˆ°ï¼Œä½†æ˜¯ä½ å¯ä»¥ä½¿ç”¨ AutoProcessor æ¥è·å–åŒ¹é…çš„å¤„ç†å™¨ç±»ï¼Œåœ¨æœ¬ä¾‹ä¸­ä¸º Blip2Processorã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ GPU æ¥åŠ å¿«æ–‡æœ¬ç”Ÿæˆé€Ÿåº¦:

```s
device = "cuda" if torch.cuda.is_available () else "cpu"
model.to (device)
```

### 4.2 å›¾åƒå­—å¹•ç”Ÿæˆ

æˆ‘ä»¬å…ˆçœ‹çœ‹ BLIP-2 æ˜¯å¦å¯ä»¥é›¶æ ·æœ¬åœ°ä¸ºã€Šçº½çº¦å®¢ã€‹å¡é€šå›¾åƒç”Ÿæˆå­—å¹•ã€‚è¦ä¸ºå›¾åƒæ·»åŠ å­—å¹•ï¼Œæˆ‘ä»¬ä¸å¿…å‘æ¨¡å‹æä¾›ä»»ä½•æ–‡æœ¬æç¤ºï¼Œä»…æä¾›é¢„å¤„ç†è¿‡çš„è¾“å…¥å›¾åƒã€‚æ²¡æœ‰ä»»ä½•æ–‡å­—æç¤ºï¼Œæ¨¡å‹å°†ä» BOS (beginning-of-sequence) å¼€å§‹ç”Ÿæˆå›¾åƒå­—å¹•ã€‚

```s
inputs = processor (image, return_tensors="pt")

generated_ids = model.generate (**inputs, max_new_tokens=20)
generated_text = processor.batch_decode (generated_ids, skip_special_tokens=True)[0].strip ()
print (generated_text)
>>>
"two cartoon monsters sitting around a campfire"
```

å¯¹äºæœªä½¿ç”¨ã€Šçº½çº¦å®¢ã€‹é£æ ¼çš„å¡é€šå›¾åƒè®­ç»ƒè¿‡çš„æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªä»¤äººå°è±¡æ·±åˆ»çš„å‡†ç¡®æè¿°ï¼

### 4.3 å›¾åƒå­—å¹•ç”Ÿæˆ

æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡æä¾›æ–‡æœ¬æç¤ºæ¥æ‰©å±•å›¾åƒå­—å¹•ç”Ÿæˆï¼Œæ¨¡å‹å°†åœ¨ç»™å®šå›¾åƒçš„æƒ…å†µä¸‹æ¥ç€æç¤ºè¯å¾€ä¸‹è¡¥å……ã€‚

```s
prompt = "this is a cartoon of"

inputs = processor (image, text=prompt, return_tensors="pt").to (device, torch.float16)

generated_ids = model.generate (**inputs, max_new_tokens=20)
generated_text = processor.batch_decode (generated_ids, skip_special_tokens=True)[0].strip ()
print (generated_text)
>>>
"two monsters sitting around a campfire"
```

```s
prompt = "they look like they are"

inputs = processor (image, text=prompt, return_tensors="pt").to (device, torch.float16)

generated_ids = model.generate (**inputs, max_new_tokens=20)
generated_text = processor.batch_decode (generated_ids, skip_special_tokens=True)[0].strip ()
print (generated_text)
>>>
"having a good time"
```

### 4.4 è§†è§‰é—®ç­”

ç”¨äºè§†è§‰é—®ç­”æ—¶ï¼Œæç¤ºå¿…é¡»éµå¾ªç‰¹å®šæ ¼å¼: "Question: {} Answer:"

```s
prompt = "Question: What is a dinosaur holding? Answer:"

inputs = processor (image, text=prompt, return_tensors="pt").to (device, torch.float16)

generated_ids = model.generate (**inputs, max_new_tokens=10)
generated_text = processor.batch_decode (generated_ids, skip_special_tokens=True)[0].strip ()
print (generated_text)
>>>
"A torch"
```

### 4.5 åŸºäºèŠå¤©çš„æç¤º

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ‹¼æ¥å¯¹è¯ä¸­æ¯è½®çš„é—®é¢˜å’Œå›ç­”æ¥åˆ›å»ºç±»ä¼¼ ChatGPT çš„ä½“éªŒã€‚æˆ‘ä»¬ç”¨æŸä¸ªæç¤º (æ¯”å¦‚ â€œæé¾™æ‹¿ç€ä»€ä¹ˆï¼Ÿâ€) æ¥é—®æ¨¡å‹ï¼Œæ¨¡å‹ä¼šä¸ºå®ƒç”Ÿæˆä¸€ä¸ªç­”æ¡ˆ (å¦‚ â€œç«ç‚¬â€)ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠè¿™ä¸€é—®ä¸€ç­”æ‹¼æ¥åˆ°å¯¹è¯ä¸­ã€‚ç„¶åæˆ‘ä»¬å†æ¥ä¸€è½®ï¼Œè¿™æ ·å°±æŠŠä¸Šä¸‹æ–‡ (context) å»ºç«‹èµ·æ¥äº†ã€‚ä½†æ˜¯ï¼Œéœ€è¦ç¡®ä¿çš„æ˜¯ï¼Œä¸Šä¸‹æ–‡ä¸èƒ½è¶…è¿‡ 512 ä¸ªæ ‡è®°ï¼Œå› ä¸ºè¿™æ˜¯ BLIP-2 ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹ (OPT å’Œ T5) çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚

```s
context = [
   ("What is a dinosaur holding?", "a torch"),
   ("Where are they?", "In the woods.")
]
question = "What for?"
template = "Question: {} Answer: {}."

prompt = "".join ([template.format (context [i][0], context [i][1]) for i in range (len (context))]) +" Question: "+ question +" Answer:"

print (prompt)
>>>
Question: What is a dinosaur holding? Answer: a torch. Question: Where are they? Answer: In the woods.. Question: What for? Answer:
```

```s
inputs = processor (image, text=prompt, return_tensors="pt").to (device, torch.float16)

generated_ids = model.generate (**inputs, max_new_tokens=10)
generated_text = processor.batch_decode (generated_ids, skip_special_tokens=True)[0].strip ()
print (generated_text)
>>>
To light a fire.
```


## å‚è€ƒ

1. [BLIP-2 æ¨¡å‹æ–‡æ¡£](https://hf.co/docs/transformers/main/en/model_doc/blip-2)
2. [ä½¿ç”¨ BLIP-2 é›¶æ ·æœ¬â€œå›¾ç”Ÿæ–‡â€](https://mp.weixin.qq.com/s/EmlsjEb0xEp8u9-rDQxqjA)

